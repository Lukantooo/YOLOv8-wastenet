{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Exploring data directory structure...\")\n",
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install ultralytics (YOLO)\n",
    "!pip install -U ultralytics\n",
    "\n",
    "# Verify installation\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "# Import required libraries\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ],
   "id": "3148f57b2195492c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load and examine the TACO annotations\n",
    "json_path = './data/annotations.json'\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "categories = data['categories']\n",
    "\n",
    "print(f\"üìä TACO Dataset Overview:\")\n",
    "print(f\"   Total images: {len(images)}\")\n",
    "print(f\"   Total annotations: {len(annotations)}\")\n",
    "print(f\"   Total categories: {len(categories)}\")\n",
    "print(f\"   Average annotations per image: {len(annotations)/len(images):.2f}\")\n",
    "\n",
    "# Show first few categories\n",
    "print(f\"\\nüè∑Ô∏è  First 10 categories:\")\n",
    "for i, cat in enumerate(categories[:10]):\n",
    "    print(f\"   {cat['id']}: {cat['name']}\")\n",
    "\n",
    "# Show dataset distribution\n",
    "print(f\"\\nüìÅ Image file structure (first 5):\")\n",
    "for img in images[:5]:\n",
    "    print(f\"   {img['file_name']} ({img['width']}x{img['height']})\")"
   ],
   "id": "61f991d90109ac52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def convert_taco_to_yolo(json_path, image_root_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Convert TACO dataset from COCO format to YOLO format\n",
    "\n",
    "    Args:\n",
    "        json_path: Path to annotations.json\n",
    "        image_root_dir: Root directory containing batch folders with images\n",
    "        output_dir: Output directory for YOLO format dataset\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üîÑ Loading TACO annotations...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images = data['images']\n",
    "    annotations = data['annotations']\n",
    "    categories = data['categories']\n",
    "\n",
    "    print(f\"Found {len(images)} images, {len(annotations)} annotations, {len(categories)} categories\")\n",
    "\n",
    "    # Create output directories\n",
    "    print(\"üìÅ Creating output directories...\")\n",
    "    os.makedirs(os.path.join(output_dir, 'images/train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images/val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels/train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels/val'), exist_ok=True)\n",
    "\n",
    "    # Split dataset into train/val\n",
    "    image_ids = [img['id'] for img in images]\n",
    "    train_ids, val_ids = train_test_split(image_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"üìä Train set: {len(train_ids)} images\")\n",
    "    print(f\"üìä Validation set: {len(val_ids)} images\")\n",
    "\n",
    "    # Create lookup dictionaries\n",
    "    image_id_to_filename = {img['id']: img['file_name'] for img in images}\n",
    "    category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "    # Create mapping from category_id to YOLO class_id (0-based indexing)\n",
    "    unique_category_ids = sorted(list(set(cat['id'] for cat in categories)))\n",
    "    category_id_to_yolo_id = {cat_id: idx for idx, cat_id in enumerate(unique_category_ids)}\n",
    "\n",
    "    print(\"üîÑ Converting images and annotations...\")\n",
    "    copied_count = 0\n",
    "    missing_count = 0\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"   Processed {i}/{len(images)} images...\")\n",
    "\n",
    "        img_id = img['id']\n",
    "        filename = img['file_name']  # This should be like \"batch_1/000001.jpg\"\n",
    "        img_width = img['width']\n",
    "        img_height = img['height']\n",
    "\n",
    "        # Determine train or val\n",
    "        if img_id in train_ids:\n",
    "            image_dir = os.path.join(output_dir, 'images/train')\n",
    "            label_dir = os.path.join(output_dir, 'labels/train')\n",
    "        else:\n",
    "            image_dir = os.path.join(output_dir, 'images/val')\n",
    "            label_dir = os.path.join(output_dir, 'labels/val')\n",
    "\n",
    "        # Construct full image path\n",
    "        full_image_path = os.path.join(image_root_dir, filename)\n",
    "\n",
    "        # Extract just the image filename for destination\n",
    "        image_filename = os.path.basename(filename)\n",
    "\n",
    "        if os.path.exists(full_image_path):\n",
    "            # Copy image\n",
    "            shutil.copy(full_image_path, os.path.join(image_dir, image_filename))\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            if missing_count < 10:  # Only print first 10 missing files\n",
    "                print(f\"‚ö†Ô∏è  Warning: Image {full_image_path} not found.\")\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "        # Create label file\n",
    "        label_filename = image_filename.replace('.jpg', '.txt').replace('.JPG', '.txt')\n",
    "        label_file = os.path.join(label_dir, label_filename)\n",
    "\n",
    "        with open(label_file, 'w') as lf:\n",
    "            for ann in annotations:\n",
    "                if ann['image_id'] == img_id:\n",
    "                    category_id = ann['category_id']\n",
    "                    yolo_class_id = category_id_to_yolo_id[category_id]\n",
    "\n",
    "                    bbox = ann['bbox']  # [x, y, width, height] in COCO format\n",
    "\n",
    "                    # Convert to YOLO format (normalized center coordinates)\n",
    "                    x_center = (bbox[0] + bbox[2] / 2) / img_width\n",
    "                    y_center = (bbox[1] + bbox[3] / 2) / img_height\n",
    "                    width = bbox[2] / img_width\n",
    "                    height = bbox[3] / img_height\n",
    "\n",
    "                    lf.write(f\"{yolo_class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Successfully copied {copied_count} images\")\n",
    "    print(f\"‚ùå Missing images: {missing_count}\")\n",
    "\n",
    "    return category_id_to_yolo_id, category_id_to_name\n",
    "\n",
    "def create_data_yaml(output_dir, categories, category_id_to_yolo_id):\n",
    "    \"\"\"Create data.yaml file for YOLO training\"\"\"\n",
    "\n",
    "    # Create class names list in YOLO order (0-based indexing)\n",
    "    class_names = [\"\"] * len(category_id_to_yolo_id)\n",
    "    for cat in categories:\n",
    "        yolo_id = category_id_to_yolo_id[cat['id']]\n",
    "        class_names[yolo_id] = cat['name']\n",
    "\n",
    "    yaml_content = f\"\"\"# TACO Dataset YOLO Configuration\n",
    "train: {os.path.abspath(os.path.join(output_dir, 'images/train'))}\n",
    "val: {os.path.abspath(os.path.join(output_dir, 'images/val'))}\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "    yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "    print(f\"üìÑ Created {yaml_path}\")\n",
    "    print(f\"üìä Number of classes: {len(class_names)}\")\n",
    "    print(\"üè∑Ô∏è  Class names:\", class_names[:10], \"...\" if len(class_names) > 10 else \"\")\n",
    "\n",
    "    return yaml_path\n",
    "\n",
    "print(\"‚úÖ Conversion functions defined!\")"
   ],
   "id": "b4ce3338be0dbc3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "json_path = './data/annotations.json'\n",
    "image_root_dir = './data'  # Directory containing batch_1, batch_2, etc.\n",
    "output_dir = './output'\n",
    "\n",
    "print(\"üöÄ Starting TACO to YOLO conversion...\")\n",
    "print(f\"üìÅ JSON path: {json_path}\")\n",
    "print(f\"üìÅ Image root: {image_root_dir}\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Convert dataset\n",
    "category_id_to_yolo_id, category_id_to_name = convert_taco_to_yolo(\n",
    "    json_path, image_root_dir, output_dir\n",
    ")\n",
    "\n",
    "# Load categories for YAML creation\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "categories = data['categories']\n",
    "\n",
    "# Create data.yaml\n",
    "yaml_path = create_data_yaml(output_dir, categories, category_id_to_yolo_id)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ Conversion complete!\")\n",
    "print(f\"üìÅ YOLO dataset created in: {output_dir}\")\n",
    "print(f\"üìÑ Configuration file: {yaml_path}\")\n",
    "print(\"=\"*50)"
   ],
   "id": "4ce231d9cb182e3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display sample images with annotations\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "def visualize_yolo_sample(output_dir, num_samples=4):\n",
    "    \"\"\"Visualize sample images with YOLO annotations\"\"\"\n",
    "\n",
    "    # Load class names\n",
    "    yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        yaml_content = f.read()\n",
    "\n",
    "    # Extract class names (simple parsing)\n",
    "    names_line = [line for line in yaml_content.split('\\n') if line.startswith('names:')][0]\n",
    "    class_names = eval(names_line.split('names: ')[1])\n",
    "\n",
    "    # Get sample training images\n",
    "    train_img_dir = os.path.join(output_dir, 'images/train')\n",
    "    train_label_dir = os.path.join(output_dir, 'labels/train')\n",
    "\n",
    "    image_files = [f for f in os.listdir(train_img_dir) if f.endswith('.jpg')]\n",
    "    sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img_file in enumerate(sample_files):\n",
    "        # Load image\n",
    "        img_path = os.path.join(train_img_dir, img_file)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Load annotations\n",
    "        label_file = img_file.replace('.jpg', '.txt')\n",
    "        label_path = os.path.join(train_label_dir, label_file)\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                annotations = f.readlines()\n",
    "\n",
    "            # Draw bounding boxes\n",
    "            for ann in annotations:\n",
    "                class_id, x_center, y_center, width, height = map(float, ann.strip().split())\n",
    "\n",
    "                # Convert from YOLO to pixel coordinates\n",
    "                x1 = int((x_center - width/2) * w)\n",
    "                y1 = int((y_center - height/2) * h)\n",
    "                x2 = int((x_center + width/2) * w)\n",
    "                y2 = int((y_center + height/2) * h)\n",
    "\n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "                # Add label\n",
    "                label = class_names[int(class_id)]\n",
    "                cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f'Sample {i+1}: {img_file}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"üìä Visualizing sample training data...\")\n",
    "visualize_yolo_sample('./output')"
   ],
   "id": "9d4d9131963aaaad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"üöÄ Starting YOLO training...\")\n",
    "\n",
    "# Initialize YOLOv8 model with pretrained weights\n",
    "#model = YOLO('yolov8n.pt')  # nano model (fastest)\n",
    "# Alternative options:\n",
    "# model = YOLO('yolov8s.pt')  # small model (better accuracy)\n",
    "model = YOLO('yolov8m.pt')  # medium model (even better accuracy)\n",
    "\n",
    "# Start training - CORRECTED PATHS\n",
    "results = model.train(\n",
    "    data='./output/data.yaml',    # Use relative path to your data.yaml\n",
    "    epochs=50,                    # Number of training epochs\n",
    "    imgsz=800,                   # Image size\n",
    "    batch=12,                    # Batch size (reduce if GPU memory issues)\n",
    "    name='taco_detection',       # Experiment name\n",
    "    patience=100,                 # Early stopping patience\n",
    "    save=True,                   # Save model checkpoints\n",
    "    plots=True,                  # Generate training plots\n",
    "    project='./runs/detect',     # Local project directory\n",
    "    device=0                     # Use GPU if available (or 'cpu' for CPU only)\n",
    ")\n",
    "\n",
    "print(\"üéâ Training complete!\")\n",
    "print(f\"üìÅ Model saved in: ./runs/detect/taco_detection\")"
   ],
   "id": "793cbd3f38906b88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the trained model\n",
    "model_path = './runs/detect/taco_detection/weights/best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(\"üìä Evaluating model performance...\")\n",
    "\n",
    "# Run validation\n",
    "metrics = model.val(data='./output/data.yaml')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéØ MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üìà mAP50 (IoU=0.5): {metrics.box.map50:.3f}\")\n",
    "print(f\"üìà mAP50-95 (IoU=0.5:0.95): {metrics.box.map:.3f}\")\n",
    "print(f\"üéØ Precision: {metrics.box.mp:.3f}\")\n",
    "print(f\"üéØ Recall: {metrics.box.mr:.3f}\")\n",
    "print(f\"‚ö° Inference Speed: {metrics.speed['inference']:.1f}ms per image\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Performance interpretation\n",
    "if metrics.box.map50 > 0.7:\n",
    "    print(\"üåü Excellent performance!\")\n",
    "elif metrics.box.map50 > 0.5:\n",
    "    print(\"‚úÖ Good performance!\")\n",
    "elif metrics.box.map50 > 0.3:\n",
    "    print(\"‚ö†Ô∏è  Moderate performance - consider more training\")\n",
    "else:\n",
    "    print(\"‚ùå Low performance - check data quality or increase training\")"
   ],
   "id": "4210bba073bd1fff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display training plots\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "print(\"üìä Training Results Visualization\")\n",
    "\n",
    "# Find result images - CORRECTED PATH\n",
    "results_dir = './runs/detect/taco_detection'\n",
    "plot_files = glob.glob(os.path.join(results_dir, '*.png'))\n",
    "\n",
    "# Display key plots\n",
    "key_plots = ['results.png', 'confusion_matrix.png', 'val_batch0_pred.png']\n",
    "\n",
    "for plot_name in key_plots:\n",
    "    plot_path = os.path.join(results_dir, plot_name)\n",
    "    if os.path.exists(plot_path):\n",
    "        print(f\"\\nüìà {plot_name.replace('_', ' ').title()}\")\n",
    "        display(Image(plot_path))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {plot_name} not found\")\n",
    "\n",
    "print(f\"\\nüìÅ All training results saved in: {results_dir}\")"
   ],
   "id": "5b1e7cb03fcc6c48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test model on validation images\n",
    "def test_on_validation_samples(model, output_dir, num_samples=6):\n",
    "    \"\"\"Test model on sample validation images\"\"\"\n",
    "\n",
    "    val_images_dir = os.path.join(output_dir, 'images/val')\n",
    "    results_dir = './inference_results'  # CORRECTED PATH\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Get sample validation images\n",
    "    val_images = [f for f in os.listdir(val_images_dir) if f.endswith('.jpg')]\n",
    "    sample_images = random.sample(val_images, min(num_samples, len(val_images)))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    print(f\"üîç Testing model on {len(sample_images)} validation images...\")\n",
    "\n",
    "    for i, img_file in enumerate(sample_images):\n",
    "        img_path = os.path.join(val_images_dir, img_file)\n",
    "\n",
    "        # Run inference\n",
    "        results = model(img_path, conf=0.25)  # Confidence threshold\n",
    "\n",
    "        # Get annotated image\n",
    "        annotated_img = results[0].plot()\n",
    "        annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Count detections\n",
    "        num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "\n",
    "        # Display\n",
    "        axes[i].imshow(annotated_img)\n",
    "        axes[i].set_title(f'{img_file}\\nDetections: {num_detections}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "        # Save annotated image\n",
    "        output_path = os.path.join(results_dir, f'annotated_{img_file}')\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Print detection details\n",
    "        if num_detections > 0:\n",
    "            print(f\"üì∑ {img_file}: {num_detections} objects detected\")\n",
    "            for j, box in enumerate(results[0].boxes):\n",
    "                class_id = int(box.cls)\n",
    "                confidence = float(box.conf)\n",
    "                class_name = model.names[class_id]\n",
    "                print(f\"   ‚îî‚îÄ {class_name}: {confidence:.2f}\")\n",
    "        else:\n",
    "            print(f\"üì∑ {img_file}: No objects detected\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"üíæ Annotated images saved to: {results_dir}\")\n",
    "\n",
    "# Run validation test\n",
    "test_on_validation_samples(model, './output')"
   ],
   "id": "82fbadee1b4eccba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test model on custom images\n",
    "def test_custom_image(model, image_path):\n",
    "    \"\"\"Test model on a specific image\"\"\"\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"‚ùå Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîç Testing model on: {os.path.basename(image_path)}\")\n",
    "\n",
    "    # Run inference\n",
    "    results = model(image_path, conf=0.25)\n",
    "\n",
    "    # Load and display original image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get annotated image\n",
    "    annotated_img = results[0].plot()\n",
    "    annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(annotated_img)\n",
    "    ax2.set_title('YOLO Detection Results')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print detection details\n",
    "    num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "    print(f\"üéØ Found {num_detections} objects:\")\n",
    "\n",
    "    if num_detections > 0:\n",
    "        for i, box in enumerate(results[0].boxes):\n",
    "            class_id = int(box.cls)\n",
    "            confidence = float(box.conf)\n",
    "            class_name = model.names[class_id]\n",
    "            print(f\"   {i+1}. {class_name} (confidence: {confidence:.2f})\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment and modify path to test custom images):\n",
    "# test_custom_image(model, './your_test_image.jpg')\n",
    "\n",
    "print(\"üí° To test custom images, use: test_custom_image(model, 'path/to/image.jpg')\")"
   ],
   "id": "40df57a826c4c072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Export model to different formats for deployment\n",
    "print(\"üì¶ Exporting model for deployment...\")\n",
    "\n",
    "export_dir = './exported_models'  # CORRECTED PATH\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Export to ONNX (cross-platform)\n",
    "try:\n",
    "    onnx_path = model.export(format='onnx', simplify=True)\n",
    "    print(f\"‚úÖ ONNX model exported: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ONNX export failed: {e}\")\n",
    "\n",
    "# Export to TensorFlow Lite (mobile deployment)\n",
    "try:\n",
    "    tflite_path = model.export(format='tflite')\n",
    "    print(f\"‚úÖ TensorFlow Lite model exported: {tflite_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå TFLite export failed: {e}\")\n",
    "\n",
    "# Export to TensorFlow SavedModel\n",
    "try:\n",
    "    saved_model_path = model.export(format='saved_model')\n",
    "    print(f\"‚úÖ TensorFlow SavedModel exported: {saved_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå SavedModel export failed: {e}\")\n",
    "\n",
    "print(\"\\nüìã Model Export Summary:\")\n",
    "print(f\"üéØ Best PyTorch model: {model_path}\")\n",
    "print(\"üì± Use TFLite for mobile apps\")\n",
    "print(\"üåê Use ONNX for web deployment\")\n",
    "print(\"‚òÅÔ∏è  Use SavedModel for TensorFlow Serving\")"
   ],
   "id": "78e503984dd2b701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create training summary report\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# You'll need to load these variables if running this cell separately\n",
    "# Uncomment and run if needed:\n",
    "# json_path = './data/annotations.json'\n",
    "# with open(json_path, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "# images = data['images']\n",
    "# annotations = data['annotations']\n",
    "# categories = data['categories']\n",
    "\n",
    "# Collect training information\n",
    "training_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"dataset\": {\n",
    "        \"name\": \"TACO\",\n",
    "        \"total_images\": len(images),\n",
    "        \"total_annotations\": len(annotations),\n",
    "        \"num_classes\": len(categories),\n",
    "        \"train_images\": len(train_ids),\n",
    "        \"val_images\": len(val_ids)\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"architecture\": \"YOLOv8n\",\n",
    "        \"pretrained\": True,\n",
    "        \"epochs\": 50,\n",
    "        \"image_size\": 640,\n",
    "        \"batch_size\": 16\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"mAP50\": float(metrics.box.map50),\n",
    "        \"mAP50_95\": float(metrics.box.map),\n",
    "        \"precision\": float(metrics.box.mp),\n",
    "        \"recall\": float(metrics.box.mr),\n",
    "        \"inference_speed_ms\": float(metrics.speed['inference'])\n",
    "    },\n",
    "    \"files\": {\n",
    "        \"model_path\": model_path,\n",
    "        \"config_path\": './output/data.yaml',\n",
    "        \"results_dir\": results_dir\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary - CORRECTED PATH\n",
    "summary_path = './training_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(training_summary, f, indent=2)\n",
    "\n",
    "print(\"üìä TRAINING COMPLETED SUCCESSFULLY! üéâ\")\n",
    "print(\"=\"*60)\n",
    "print(\"üìã SUMMARY:\")\n",
    "print(f\"   üéØ Final mAP50: {metrics.box.map50:.3f}\")\n",
    "print(f\"   ‚ö° Inference Speed: {metrics.speed['inference']:.1f}ms\")\n",
    "print(f\"   üìÅ Model Location: {model_path}\")\n",
    "print(f\"   üìÑ Summary Report: {summary_path}\")\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ Your TACO object detection model is ready to use!\")\n",
    "\n",
    "# Display final class distribution\n",
    "print(f\"\\nüè∑Ô∏è  DETECTED CLASSES ({len(categories)} total):\")\n",
    "for i, cat in enumerate(categories[:20]):  # Show first 20\n",
    "    yolo_id = category_id_to_yolo_id[cat['id']]\n",
    "    print(f\"   {yolo_id:2d}: {cat['name']}\")\n",
    "if len(categories) > 20:\n",
    "    print(f\"   ... and {len(categories)-20} more classes\")"
   ],
   "id": "2aa271b2e1af9da3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
