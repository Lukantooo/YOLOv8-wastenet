{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 1: Setup and Installation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Exploring data directory structure...\")\n",
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "id": "ea347e4c88dc41eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 2: Install Required Libraries\n",
    "!pip install -U ultralytics\n",
    "\n",
    "# Import required libraries\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import defaultdict, Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Verify installation\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ],
   "id": "e71fdbbbbb46a32c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 3: Examine TACO Dataset\n",
    "# Load and examine the TACO annotations\n",
    "json_path = './data/annotations.json'\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "categories = data['categories']\n",
    "\n",
    "print(f\"üìä TACO Dataset Overview:\")\n",
    "print(f\"   Total images: {len(images)}\")\n",
    "print(f\"   Total annotations: {len(annotations)}\")\n",
    "print(f\"   Total categories: {len(categories)}\")\n",
    "print(f\"   Average annotations per image: {len(annotations)/len(images):.2f}\")\n",
    "\n",
    "# Show first few categories\n",
    "print(f\"\\nüè∑Ô∏è  First 10 categories:\")\n",
    "for i, cat in enumerate(categories[:10]):\n",
    "    print(f\"   {cat['id']}: {cat['name']}\")\n",
    "\n",
    "# Show dataset distribution\n",
    "print(f\"\\nüìÅ Image file structure (first 5):\")\n",
    "for img in images[:5]:\n",
    "    print(f\"   {img['file_name']} ({img['width']}x{img['height']})\")"
   ],
   "id": "7a7f92a5d8cce695",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 3a: Count Available Images in Batch Folders\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_images_in_batches(data_dir='./data'):\n",
    "    \"\"\"Count actual images available in batch folders\"\"\"\n",
    "\n",
    "    print(\"üìÅ Counting images in batch folders...\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    batch_counts = defaultdict(int)\n",
    "    total_images = 0\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n",
    "\n",
    "    # Look for batch folders\n",
    "    batch_folders = []\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)\n",
    "        if os.path.isdir(item_path) and 'batch' in item.lower():\n",
    "            batch_folders.append(item)\n",
    "\n",
    "    batch_folders.sort()  # Sort for consistent output\n",
    "\n",
    "    if not batch_folders:\n",
    "        print(\"‚ö†Ô∏è  No batch folders found in ./data/\")\n",
    "        return 0, {}\n",
    "\n",
    "    # Count images in each batch folder\n",
    "    for batch_folder in batch_folders:\n",
    "        batch_path = os.path.join(data_dir, batch_folder)\n",
    "\n",
    "        # Count image files\n",
    "        image_count = 0\n",
    "        for file in os.listdir(batch_path):\n",
    "            if any(file.endswith(ext) for ext in image_extensions):\n",
    "                image_count += 1\n",
    "\n",
    "        batch_counts[batch_folder] = image_count\n",
    "        total_images += image_count\n",
    "\n",
    "        print(f\"   üìÇ {batch_folder}: {image_count:,} images\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"üìä TOTAL IMAGES AVAILABLE: {total_images:,}\")\n",
    "\n",
    "    return total_images, dict(batch_counts)\n",
    "\n",
    "def compare_with_annotations(total_available, annotations):\n",
    "    \"\"\"Compare available images with annotation records\"\"\"\n",
    "\n",
    "    print(\"\\nüîç ANNOTATION vs AVAILABLE COMPARISON:\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    annotated_count = len([img for img in annotations if 'file_name' in img])\n",
    "\n",
    "    print(f\"üìÑ Images in annotations.json: {annotated_count:,}\")\n",
    "    print(f\"üìÅ Images in batch folders:    {total_available:,}\")\n",
    "\n",
    "    if total_available == annotated_count:\n",
    "        print(\"‚úÖ Perfect match! All annotated images are available\")\n",
    "        availability = 100.0\n",
    "    elif total_available > annotated_count:\n",
    "        extra = total_available - annotated_count\n",
    "        print(f\"üìà You have {extra:,} extra images (not in annotations)\")\n",
    "        availability = (annotated_count / total_available) * 100\n",
    "    else:\n",
    "        missing = annotated_count - total_available\n",
    "        print(f\"‚ö†Ô∏è  {missing:,} annotated images are missing from folders\")\n",
    "        availability = (total_available / annotated_count) * 100\n",
    "\n",
    "    print(f\"üìä Availability rate: {availability:.1f}%\")\n",
    "\n",
    "    return availability\n",
    "\n",
    "# Run the image counting\n",
    "total_available, batch_counts = count_images_in_batches()\n",
    "\n",
    "if total_available > 0:\n",
    "    # Compare with annotations\n",
    "    availability = compare_with_annotations(total_available, images)\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\nüí° SUMMARY:\")\n",
    "    if availability >= 95:\n",
    "        print(\"   üéØ Excellent! Ready for training\")\n",
    "    elif availability >= 80:\n",
    "        print(\"   ‚úÖ Good availability, should work well\")\n",
    "    elif availability >= 60:\n",
    "        print(\"   ‚ö†Ô∏è  Some images missing, but usable\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Many images missing, check data setup\")\n",
    "\n",
    "    print(f\"   üìä Dataset size: {total_available:,} images across {len(batch_counts)} batches\")\n",
    "\n",
    "    # Show largest batches\n",
    "    if len(batch_counts) > 1:\n",
    "        largest_batches = sorted(batch_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        print(f\"   üìà Largest batches: {', '.join([f'{b}({c})' for b, c in largest_batches])}\")"
   ],
   "id": "182ca41d6280a4b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 4: Define Class Mapping and Conversion Functions (FIXED VERSION)\n",
    "def create_class_mapping():\n",
    "    \"\"\"Create mapping from original TACO classes to consolidated categories\"\"\"\n",
    "\n",
    "    class_mapping = {\n",
    "        # Bottle category\n",
    "        'Clear plastic bottle': 'Bottle',\n",
    "        'Glass bottle': 'Bottle',\n",
    "        'Other plastic bottle': 'Bottle',\n",
    "\n",
    "        # Bottle cap category\n",
    "        'Plastic bottle cap': 'Bottle cap',\n",
    "        'Metal bottle cap': 'Bottle cap',\n",
    "\n",
    "        # Can category\n",
    "        'Drink can': 'Can',\n",
    "        'Food Can': 'Can',\n",
    "\n",
    "        # Cigarette category\n",
    "        'Cigarette': 'Cigarette',\n",
    "\n",
    "        # Cup category\n",
    "        'Paper cup': 'Cup',\n",
    "        'Disposable plastic cup': 'Cup',\n",
    "        'Foam cup': 'Cup',\n",
    "        'Glass cup': 'Cup',\n",
    "        'Other plastic cup': 'Cup',\n",
    "\n",
    "        # Lid category\n",
    "        'Plastic lid': 'Lid',\n",
    "        'Metal lid': 'Lid',\n",
    "\n",
    "        # Plastic bag + wrapper category\n",
    "        'Garbage bag': 'Plastic bag + wrapper',\n",
    "        'Single-use carrier bag': 'Plastic bag + wrapper',\n",
    "        'Polypropylene bag': 'Plastic bag + wrapper',\n",
    "        'Produce bag': 'Plastic bag + wrapper',\n",
    "        'Cereal bag': 'Plastic bag + wrapper',\n",
    "        'Bread bag': 'Plastic bag + wrapper',\n",
    "        'Plastic film': 'Plastic bag + wrapper',\n",
    "        'Crisp packet': 'Plastic bag + wrapper',\n",
    "        'Other plastic wrapper': 'Plastic bag + wrapper',\n",
    "        'Retort pouch': 'Plastic bag + wrapper',\n",
    "        'Six pack rings': 'Plastic bag + wrapper',\n",
    "\n",
    "        # Pop tab category\n",
    "        'Pop tab': 'Pop tab',\n",
    "\n",
    "        # Straw category\n",
    "        'Plastic straw': 'Straw',\n",
    "        'Paper straw': 'Straw',\n",
    "\n",
    "        # Other category (everything else)\n",
    "        'Aluminium foil': 'Other',\n",
    "        'Battery': 'Other',\n",
    "        'Aluminium blister pack': 'Other',\n",
    "        'Carded blister pack': 'Other',\n",
    "        'Broken glass': 'Other',\n",
    "        'Corrugated carton': 'Other',\n",
    "        'Drink carton': 'Other',\n",
    "        'Egg carton': 'Other',\n",
    "        'Meal carton': 'Other',\n",
    "        'Other carton': 'Other',\n",
    "        'Food waste': 'Other',\n",
    "        'Magazine paper': 'Other',\n",
    "        'Tissues': 'Other',\n",
    "        'Wrapping paper': 'Other',\n",
    "        'Normal paper': 'Other',\n",
    "        'Paper bag': 'Other',\n",
    "        'Plastified paper bag': 'Other',\n",
    "        'Pizza box': 'Other',\n",
    "        'Spread tub': 'Other',\n",
    "        'Tupperware': 'Other',\n",
    "        'Disposable food container': 'Other',\n",
    "        'Foam food container': 'Other',\n",
    "        'Other plastic container': 'Other',\n",
    "        'Plastic gloves': 'Other',\n",
    "        'Plastic glooves': 'Other',  # Handle the typo in your data\n",
    "        'Plastic utensils': 'Other',\n",
    "        'Rope & strings': 'Other',\n",
    "        'Scrap metal': 'Other',\n",
    "        'Shoe': 'Other',\n",
    "        'Squeezable tube': 'Other',\n",
    "        'Styrofoam piece': 'Other',\n",
    "        'Toilet tube': 'Other',\n",
    "        'Unlabeled litter': 'Other',\n",
    "        'Glass jar': 'Other',\n",
    "        'Other plastic': 'Other',\n",
    "        'Aerosol': 'Other'  # Handle the unmapped class found in your data\n",
    "    }\n",
    "\n",
    "    return class_mapping\n",
    "\n",
    "def analyze_class_distribution(annotations, categories, class_mapping):\n",
    "    \"\"\"Analyze class distribution before and after mapping\"\"\"\n",
    "\n",
    "    print(\"üìä Class Distribution Analysis\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Count original classes\n",
    "    original_counts = Counter()\n",
    "    category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "    for ann in annotations:\n",
    "        category_name = category_id_to_name[ann['category_id']]\n",
    "        original_counts[category_name] += 1\n",
    "\n",
    "    # Count mapped classes\n",
    "    mapped_counts = Counter()\n",
    "    for ann in annotations:\n",
    "        category_name = category_id_to_name[ann['category_id']]\n",
    "        mapped_category = class_mapping.get(category_name, 'Other')\n",
    "        mapped_counts[mapped_category] += 1\n",
    "\n",
    "    print(f\"üìà Original classes: {len(original_counts)} classes\")\n",
    "    print(f\"üìà Mapped classes: {len(mapped_counts)} classes\")\n",
    "    print(f\"üîÑ Reduction: {len(original_counts) - len(mapped_counts)} classes removed\")\n",
    "\n",
    "    print(f\"\\nüè∑Ô∏è  Mapped Class Distribution:\")\n",
    "    for category, count in sorted(mapped_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / sum(mapped_counts.values())) * 100\n",
    "        print(f\"   {category:25}: {count:5} annotations ({percentage:5.1f}%)\")\n",
    "\n",
    "    return original_counts, mapped_counts\n",
    "\n",
    "def convert_taco_to_yolo_with_mapping_fixed(json_path, image_root_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Convert TACO dataset from COCO format to YOLO format with class mapping\n",
    "    FIXED: Prevents filename collisions by including batch name in filename\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üîÑ Loading TACO annotations...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images = data['images']\n",
    "    annotations = data['annotations']\n",
    "    categories = data['categories']\n",
    "\n",
    "    print(f\"Found {len(images)} images, {len(annotations)} annotations, {len(categories)} categories\")\n",
    "\n",
    "    # Create class mapping\n",
    "    class_mapping = create_class_mapping()\n",
    "\n",
    "    # Analyze class distribution\n",
    "    original_counts, mapped_counts = analyze_class_distribution(annotations, categories, class_mapping)\n",
    "\n",
    "    # Create output directories\n",
    "    print(\"\\nüìÅ Creating output directories...\")\n",
    "    os.makedirs(os.path.join(output_dir, 'images/train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images/val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels/train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels/val'), exist_ok=True)\n",
    "\n",
    "    # Split dataset into train/val\n",
    "    image_ids = [img['id'] for img in images]\n",
    "    train_ids, val_ids = train_test_split(image_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"üìä Train set: {len(train_ids)} images\")\n",
    "    print(f\"üìä Validation set: {len(val_ids)} images\")\n",
    "\n",
    "    # Create lookup dictionaries\n",
    "    image_id_to_filename = {img['id']: img['file_name'] for img in images}\n",
    "    category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "    # Create mapped categories and YOLO class mapping\n",
    "    mapped_categories = sorted(list(set(class_mapping.values())))\n",
    "    mapped_category_to_yolo_id = {cat: idx for idx, cat in enumerate(mapped_categories)}\n",
    "\n",
    "    print(f\"\\nüè∑Ô∏è  Final mapped categories ({len(mapped_categories)}):\")\n",
    "    for i, cat in enumerate(mapped_categories):\n",
    "        print(f\"   {i}: {cat}\")\n",
    "\n",
    "    print(\"\\nüîÑ Converting images and annotations...\")\n",
    "    copied_count = 0\n",
    "    missing_count = 0\n",
    "    collision_count = 0\n",
    "    conversion_stats = defaultdict(int)\n",
    "\n",
    "    # Track renamed files for label creation\n",
    "    old_to_new_filename = {}\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"   Processed {i}/{len(images)} images...\")\n",
    "\n",
    "        img_id = img['id']\n",
    "        filename = img['file_name']  # e.g., \"batch_1/000000.jpg\"\n",
    "        img_width = img['width']\n",
    "        img_height = img['height']\n",
    "\n",
    "        # Determine train or val\n",
    "        if img_id in train_ids:\n",
    "            image_dir = os.path.join(output_dir, 'images/train')\n",
    "            label_dir = os.path.join(output_dir, 'labels/train')\n",
    "        else:\n",
    "            image_dir = os.path.join(output_dir, 'images/val')\n",
    "            label_dir = os.path.join(output_dir, 'labels/val')\n",
    "\n",
    "        # Construct full image path\n",
    "        full_image_path = os.path.join(image_root_dir, filename)\n",
    "\n",
    "        # FIXED: Create unique filename to prevent collisions\n",
    "        # Extract batch name and original filename\n",
    "        if '/' in filename:\n",
    "            batch_name, original_filename = filename.split('/', 1)\n",
    "        else:\n",
    "            batch_name = 'root'\n",
    "            original_filename = filename\n",
    "\n",
    "        # Create new unique filename: batch_name + \"_\" + original_filename\n",
    "        # batch_1/000000.jpg ‚Üí batch_1_000000.jpg\n",
    "        new_filename = f\"{batch_name}_{original_filename}\"\n",
    "\n",
    "        # Store mapping for label file creation\n",
    "        old_to_new_filename[filename] = new_filename\n",
    "\n",
    "        # Check for existing file with same new name (shouldn't happen, but safety check)\n",
    "        destination_path = os.path.join(image_dir, new_filename)\n",
    "        if os.path.exists(destination_path):\n",
    "            collision_count += 1\n",
    "            # Add image ID to make it unique\n",
    "            name_part, ext = os.path.splitext(new_filename)\n",
    "            new_filename = f\"{name_part}_id{img_id}{ext}\"\n",
    "            destination_path = os.path.join(image_dir, new_filename)\n",
    "            old_to_new_filename[filename] = new_filename\n",
    "\n",
    "        if os.path.exists(full_image_path):\n",
    "            # Copy image with new unique name\n",
    "            shutil.copy(full_image_path, destination_path)\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            if missing_count < 10:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Image {full_image_path} not found.\")\n",
    "            missing_count += 1\n",
    "            continue\n",
    "\n",
    "        # Create label file with mapped classes\n",
    "        label_filename = new_filename.replace('.jpg', '.txt').replace('.JPG', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n",
    "        label_file = os.path.join(label_dir, label_filename)\n",
    "\n",
    "        with open(label_file, 'w') as lf:\n",
    "            for ann in annotations:\n",
    "                if ann['image_id'] == img_id:\n",
    "                    # Get original category name\n",
    "                    original_category = category_id_to_name[ann['category_id']]\n",
    "\n",
    "                    # Map to new category\n",
    "                    mapped_category = class_mapping.get(original_category, 'Other')\n",
    "                    yolo_class_id = mapped_category_to_yolo_id[mapped_category]\n",
    "\n",
    "                    # Track conversion statistics\n",
    "                    conversion_stats[f\"{original_category} -> {mapped_category}\"] += 1\n",
    "\n",
    "                    bbox = ann['bbox']  # [x, y, width, height] in COCO format\n",
    "\n",
    "                    # Convert to YOLO format (normalized center coordinates)\n",
    "                    x_center = (bbox[0] + bbox[2] / 2) / img_width\n",
    "                    y_center = (bbox[1] + bbox[3] / 2) / img_height\n",
    "                    width = bbox[2] / img_width\n",
    "                    height = bbox[3] / img_height\n",
    "\n",
    "                    lf.write(f\"{yolo_class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Successfully copied {copied_count} images\")\n",
    "    print(f\"‚ùå Missing images: {missing_count}\")\n",
    "    if collision_count > 0:\n",
    "        print(f\"üîÑ Resolved filename collisions: {collision_count}\")\n",
    "\n",
    "    return mapped_category_to_yolo_id, mapped_categories, class_mapping, conversion_stats\n",
    "\n",
    "def create_data_yaml_with_mapping_fixed(output_dir, mapped_categories, mapped_category_to_yolo_id):\n",
    "    \"\"\"Create data.yaml file for YOLO training with mapped classes\"\"\"\n",
    "\n",
    "    # Create class names list in YOLO order\n",
    "    class_names = [\"\"] * len(mapped_category_to_yolo_id)\n",
    "    for category, yolo_id in mapped_category_to_yolo_id.items():\n",
    "        class_names[yolo_id] = category\n",
    "\n",
    "    yaml_content = f\"\"\"# TACO Dataset YOLO Configuration (Mapped Classes - Fixed Collisions)\n",
    "train: {os.path.abspath(os.path.join(output_dir, 'images/train'))}\n",
    "val: {os.path.abspath(os.path.join(output_dir, 'images/val'))}\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "    yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "    print(f\"\\nüìÑ Created {yaml_path}\")\n",
    "    print(f\"üìä Number of mapped classes: {len(class_names)}\")\n",
    "    print(\"üè∑Ô∏è  Final class names:\", class_names)\n",
    "\n",
    "    return yaml_path\n",
    "\n",
    "def save_mapping_info(output_dir, class_mapping, conversion_stats, mapped_counts):\n",
    "    \"\"\"Save class mapping information for reference\"\"\"\n",
    "\n",
    "    mapping_info = {\n",
    "        \"class_mapping\": class_mapping,\n",
    "        \"conversion_statistics\": dict(conversion_stats),\n",
    "        \"final_class_distribution\": dict(mapped_counts),\n",
    "        \"total_mapped_classes\": len(set(class_mapping.values()))\n",
    "    }\n",
    "\n",
    "    mapping_path = os.path.join(output_dir, 'class_mapping_info.json')\n",
    "    with open(mapping_path, 'w') as f:\n",
    "        json.dump(mapping_info, f, indent=2)\n",
    "\n",
    "    print(f\"üìã Class mapping info saved to: {mapping_path}\")\n",
    "\n",
    "print(\"‚úÖ FIXED class mapping and conversion functions defined!\")\n",
    "print(\"üîß Filename collisions will be prevented by including batch names\")"
   ],
   "id": "5b0895f562e49719",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 5: Convert TACO to YOLO with Class Mapping (FIXED VERSION)\n",
    "# Clean old output first\n",
    "import shutil\n",
    "if os.path.exists('./output'):\n",
    "    shutil.rmtree('./output')\n",
    "    print(\"üßπ Cleaned old output directory\")\n",
    "\n",
    "json_path = './data/annotations.json'\n",
    "image_root_dir = './data'\n",
    "output_dir = './output'\n",
    "\n",
    "print(\"üöÄ Starting TACO to YOLO conversion with class mapping (FIXED)...\")\n",
    "print(f\"üìÅ JSON path: {json_path}\")\n",
    "print(f\"üìÅ Image root: {image_root_dir}\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Convert dataset with mapping (FIXED VERSION)\n",
    "mapped_category_to_yolo_id, mapped_categories, class_mapping, conversion_stats = convert_taco_to_yolo_with_mapping_fixed(\n",
    "    json_path, image_root_dir, output_dir\n",
    ")\n",
    "\n",
    "# Create data.yaml with mapped classes\n",
    "yaml_path = create_data_yaml_with_mapping_fixed(output_dir, mapped_categories, mapped_category_to_yolo_id)\n",
    "\n",
    "# Load original data for saving mapping info\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Analyze final distribution\n",
    "annotations = data['annotations']\n",
    "categories = data['categories']\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "mapped_counts = Counter()\n",
    "for ann in annotations:\n",
    "    category_name = category_id_to_name[ann['category_id']]\n",
    "    mapped_category = class_mapping.get(category_name, 'Other')\n",
    "    mapped_counts[mapped_category] += 1\n",
    "\n",
    "# Save mapping information\n",
    "save_mapping_info(output_dir, class_mapping, conversion_stats, mapped_counts)\n",
    "\n",
    "# Store train/val split for later use\n",
    "image_ids = [img['id'] for img in images]\n",
    "train_ids, val_ids = train_test_split(image_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Conversion with class mapping complete! (COLLISION-FREE)\")\n",
    "print(f\"üìÅ YOLO dataset created in: {output_dir}\")\n",
    "print(f\"üìÑ Configuration file: {yaml_path}\")\n",
    "print(f\"üîÑ Classes reduced from {len(categories)} to {len(mapped_categories)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display the class mapping summary\n",
    "print(\"\\nüìã CLASS MAPPING SUMMARY:\")\n",
    "print(f\"   Original TACO classes: {len(categories)} classes\")\n",
    "print(f\"   Mapped to: {len(mapped_categories)} categories\")\n",
    "print(f\"   Categories: {', '.join(mapped_categories)}\")\n",
    "\n",
    "# Check actual dataset size created\n",
    "train_images = len([f for f in os.listdir('./output/images/train') if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "val_images = len([f for f in os.listdir('./output/images/val') if f.endswith(('.jpg', '.jpeg', '.png'))])\n"
   ],
   "id": "bcc82c48d3769ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 6: Visualize Sample Images with Mapped Classes\n",
    "import random\n",
    "\n",
    "def visualize_yolo_sample_mapped(output_dir, num_samples=4):\n",
    "    \"\"\"Visualize sample images with YOLO annotations using mapped classes\"\"\"\n",
    "\n",
    "    # Load class names\n",
    "    yaml_path = os.path.join(output_dir, 'data.yaml')\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        yaml_content = f.read()\n",
    "\n",
    "    # Extract class names (simple parsing)\n",
    "    names_line = [line for line in yaml_content.split('\\n') if line.startswith('names:')][0]\n",
    "    class_names = eval(names_line.split('names: ')[1])\n",
    "\n",
    "    # Get sample training images\n",
    "    train_img_dir = os.path.join(output_dir, 'images/train')\n",
    "    train_label_dir = os.path.join(output_dir, 'labels/train')\n",
    "\n",
    "    image_files = [f for f in os.listdir(train_img_dir) if f.endswith('.jpg')]\n",
    "    sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    print(f\"üìä Visualizing sample training data with {len(class_names)} mapped classes...\")\n",
    "\n",
    "    for i, img_file in enumerate(sample_files):\n",
    "        # Load image\n",
    "        img_path = os.path.join(train_img_dir, img_file)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Load annotations\n",
    "        label_file = img_file.replace('.jpg', '.txt').replace('.JPG', '.txt')\n",
    "        label_path = os.path.join(train_label_dir, label_file)\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                annotations = f.readlines()\n",
    "\n",
    "            # Draw bounding boxes\n",
    "            colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
    "                     (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0),\n",
    "                     (0, 128, 0), (128, 128, 128)]  # Different colors for each class\n",
    "\n",
    "            for ann in annotations:\n",
    "                class_id, x_center, y_center, width, height = map(float, ann.strip().split())\n",
    "                class_id = int(class_id)\n",
    "\n",
    "                # Convert from YOLO to pixel coordinates\n",
    "                x1 = int((x_center - width/2) * w)\n",
    "                y1 = int((y_center - height/2) * h)\n",
    "                x2 = int((x_center + width/2) * w)\n",
    "                y2 = int((y_center + height/2) * h)\n",
    "\n",
    "                # Use different color for each class\n",
    "                color = colors[class_id % len(colors)]\n",
    "\n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                # Add label with class name\n",
    "                label = class_names[class_id]\n",
    "                cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f'Sample {i+1}: {img_file}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"üè∑Ô∏è  Mapped classes being detected: {class_names}\")\n",
    "\n",
    "# Visualize samples with mapped classes\n",
    "visualize_yolo_sample_mapped('./output')"
   ],
   "id": "dacc541cd2a725ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 7: Enhanced YOLO Training with Mapped Classes\n",
    "print(\"üöÄ Starting YOLO training with mapped classes...\")\n",
    "\n",
    "# Initialize YOLOv8 model with pretrained weights\n",
    "model = YOLO('yolov8l.pt')  #large model\n",
    "\n",
    "# Enhanced training configuration for mapped classes\n",
    "results = model.train(\n",
    "    data='./output/data.yaml',\n",
    "    epochs=200,\n",
    "    imgsz=800,\n",
    "    batch=8,\n",
    "    name='taco_detection_extended',  # New experiment name\n",
    "    device=0,\n",
    ")\n",
    "\n",
    "print(\"üéâ Training complete!\")\n",
    "print(f\"üìÅ Model saved in: ./runs/detect/taco_detection_mapped_fixed\")"
   ],
   "id": "a3b0df0600be1c0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 8: Enhanced Model Evaluation (Train + Validation)\n",
    "import yaml\n",
    "\n",
    "# Load the trained model\n",
    "model_path = './runs/detect/taco_detection_augmented/weights/best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(\"üìä Comprehensive Model Evaluation (Train + Validation)\")\n",
    "\n",
    "# 1. Evaluate on VALIDATION set\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç VALIDATION SET PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "val_metrics = model.val(data='./output/data.yaml', split='val')\n",
    "\n",
    "print(f\"üìà Validation mAP50: {val_metrics.box.map50:.3f}\")\n",
    "print(f\"üìà Validation mAP50-95: {val_metrics.box.map:.3f}\")\n",
    "print(f\"üéØ Validation Precision: {val_metrics.box.mp:.3f}\")\n",
    "print(f\"üéØ Validation Recall: {val_metrics.box.mr:.3f}\")\n",
    "print(f\"‚ö° Inference Speed: {val_metrics.speed['inference']:.1f}ms\")\n",
    "\n",
    "# 2. Evaluate on TRAINING set\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç TRAINING SET PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create temporary data.yaml for training evaluation\n",
    "with open('./output/data.yaml', 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "# Create modified config pointing to train set for both train and val\n",
    "train_config = data_config.copy()\n",
    "train_config['val'] = data_config['train']  # Point validation to train folder\n",
    "\n",
    "# Save temporary config\n",
    "temp_config_path = './output/data_train_eval.yaml'\n",
    "with open(temp_config_path, 'w') as f:\n",
    "    yaml.dump(train_config, f)\n",
    "\n",
    "# Evaluate on training set\n",
    "train_metrics = model.val(data=temp_config_path, split='val')  # Uses train data as \"val\"\n",
    "\n",
    "print(f\"üìà Training mAP50: {train_metrics.box.map50:.3f}\")\n",
    "print(f\"üìà Training mAP50-95: {train_metrics.box.map:.3f}\")\n",
    "print(f\"üéØ Training Precision: {train_metrics.box.mp:.3f}\")\n",
    "print(f\"üéØ Training Recall: {train_metrics.box.mr:.3f}\")\n",
    "\n",
    "# Clean up temporary file\n",
    "os.remove(temp_config_path)\n",
    "\n",
    "# 3. Compare Train vs Validation Performance\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TRAIN vs VALIDATION COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def performance_analysis(train_map50, val_map50, train_map, val_map):\n",
    "    \"\"\"Analyze overfitting based on train vs val performance\"\"\"\n",
    "\n",
    "    map50_diff = train_map50 - val_map50\n",
    "    map_diff = train_map - val_map\n",
    "\n",
    "    print(f\"üìà mAP50 Difference (Train - Val): {map50_diff:+.3f}\")\n",
    "    print(f\"üìà mAP50-95 Difference (Train - Val): {map_diff:+.3f}\")\n",
    "\n",
    "    # Overfitting analysis\n",
    "    if map50_diff > 0.15:\n",
    "        print(\"‚ö†Ô∏è  SEVERE OVERFITTING detected!\")\n",
    "        print(\"   ‚Üí Model memorized training data\")\n",
    "        print(\"   ‚Üí Consider: more augmentation, dropout, early stopping\")\n",
    "    elif map50_diff > 0.08:\n",
    "        print(\"üü° MODERATE OVERFITTING detected\")\n",
    "        print(\"   ‚Üí Model performs much better on training data\")\n",
    "        print(\"   ‚Üí Consider: more regularization, data augmentation\")\n",
    "    elif map50_diff > 0.03:\n",
    "        print(\"üü¢ SLIGHT OVERFITTING (normal)\")\n",
    "        print(\"   ‚Üí Expected small gap between train and validation\")\n",
    "    elif map50_diff > -0.02:\n",
    "        print(\"‚úÖ WELL-BALANCED model\")\n",
    "        print(\"   ‚Üí Good generalization, minimal overfitting\")\n",
    "    else:\n",
    "        print(\"üî¥ UNDERFITTING detected\")\n",
    "        print(\"   ‚Üí Model performs better on validation than training\")\n",
    "        print(\"   ‚Üí Consider: longer training, less regularization\")\n",
    "\n",
    "    return map50_diff, map_diff\n",
    "\n",
    "# Perform analysis\n",
    "map50_diff, map_diff = performance_analysis(\n",
    "    train_metrics.box.map50, val_metrics.box.map50,\n",
    "    train_metrics.box.map, val_metrics.box.map\n",
    ")\n",
    "\n",
    "# 4. Detailed Performance Breakdown\n",
    "print(f\"\\nüìã DETAILED PERFORMANCE BREAKDOWN:\")\n",
    "print(f\"{'Metric':<20} {'Training':<12} {'Validation':<12} {'Difference':<12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'mAP50':<20} {train_metrics.box.map50:<12.3f} {val_metrics.box.map50:<12.3f} {train_metrics.box.map50-val_metrics.box.map50:<+12.3f}\")\n",
    "print(f\"{'mAP50-95':<20} {train_metrics.box.map:<12.3f} {val_metrics.box.map:<12.3f} {train_metrics.box.map-val_metrics.box.map:<+12.3f}\")\n",
    "print(f\"{'Precision':<20} {train_metrics.box.mp:<12.3f} {val_metrics.box.mp:<12.3f} {train_metrics.box.mp-val_metrics.box.mp:<+12.3f}\")\n",
    "print(f\"{'Recall':<20} {train_metrics.box.mr:<12.3f} {val_metrics.box.mr:<12.3f} {train_metrics.box.mr-val_metrics.box.mr:<+12.3f}\")\n",
    "\n",
    "# Enhanced performance interpretation for mapped classes\n",
    "print(f\"\\nüéØ OVERALL ASSESSMENT:\")\n",
    "if val_metrics.box.map50 > 0.7:\n",
    "    print(\"üåü Excellent performance! Dataset fix worked amazingly!\")\n",
    "elif val_metrics.box.map50 > 0.5:\n",
    "    print(\"‚úÖ Good performance! Much better with full dataset!\")\n",
    "elif val_metrics.box.map50 > 0.3:\n",
    "    print(\"‚ö†Ô∏è  Moderate performance - improvement from dataset fix visible\")\n",
    "else:\n",
    "    print(\"‚ùå Still low performance - may need more training or larger model\")\n",
    "\n",
    "print(\"\\nüéâ Comprehensive evaluation complete!\")"
   ],
   "id": "a0df442744179473",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 9: Display Training Plots\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "print(\"üìä Training Results Visualization\")\n",
    "\n",
    "# Find result images\n",
    "results_dir = './runs/detect/taco_detection_mapped_fixed'\n",
    "plot_files = glob.glob(os.path.join(results_dir, '*.png'))\n",
    "\n",
    "# Display key plots\n",
    "key_plots = ['results.png', 'confusion_matrix.png', 'val_batch0_pred.png']\n",
    "\n",
    "for plot_name in key_plots:\n",
    "    plot_path = os.path.join(results_dir, plot_name)\n",
    "    if os.path.exists(plot_path):\n",
    "        print(f\"\\nüìà {plot_name.replace('_', ' ').title()}\")\n",
    "        display(Image(plot_path))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {plot_name} not found\")\n",
    "\n",
    "print(f\"\\nüìÅ All training results saved in: {results_dir}\")"
   ],
   "id": "ff7ccd7d666f61ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 10: Test on Validation Samples\n",
    "def test_on_validation_samples(model, output_dir, num_samples=6):\n",
    "    \"\"\"Test model on sample validation images\"\"\"\n",
    "\n",
    "    val_images_dir = os.path.join(output_dir, 'images/val')\n",
    "    results_dir = './inference_results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Get sample validation images\n",
    "    val_images = [f for f in os.listdir(val_images_dir) if f.endswith('.jpg')]\n",
    "    sample_images = random.sample(val_images, min(num_samples, len(val_images)))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    print(f\"üîç Testing model on {len(sample_images)} validation images...\")\n",
    "\n",
    "    for i, img_file in enumerate(sample_images):\n",
    "        img_path = os.path.join(val_images_dir, img_file)\n",
    "\n",
    "        # Run inference\n",
    "        results = model(img_path, conf=0.25)  # Confidence threshold\n",
    "\n",
    "        # Get annotated image\n",
    "        annotated_img = results[0].plot()\n",
    "        annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Count detections\n",
    "        num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "\n",
    "        # Display\n",
    "        axes[i].imshow(annotated_img)\n",
    "        axes[i].set_title(f'{img_file}\\nDetections: {num_detections}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "        # Save annotated image\n",
    "        output_path = os.path.join(results_dir, f'annotated_{img_file}')\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Print detection details\n",
    "        if num_detections > 0:\n",
    "            print(f\"üì∑ {img_file}: {num_detections} objects detected\")\n",
    "            for j, box in enumerate(results[0].boxes):\n",
    "                class_id = int(box.cls)\n",
    "                confidence = float(box.conf)\n",
    "                class_name = model.names[class_id]\n",
    "                print(f\"   ‚îî‚îÄ {class_name}: {confidence:.2f}\")\n",
    "        else:\n",
    "            print(f\"üì∑ {img_file}: No objects detected\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"üíæ Annotated images saved to: {results_dir}\")\n",
    "\n",
    "# Run validation test\n",
    "test_on_validation_samples(model, './output')"
   ],
   "id": "b7b1d89725f96e85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 11: Test Custom Images Function\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/home/cupo-ubuntu/Schreibtisch/ML4B/wastenet-website/backend/taco_model.pt\"  # Update this path\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "\n",
    "def test_custom_image(model, image_path):\n",
    "    \"\"\"Test model on a specific image\"\"\"\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"‚ùå Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîç Testing model on: {os.path.basename(image_path)}\")\n",
    "\n",
    "    # Run inference\n",
    "    results = model(image_path, conf=0.25)\n",
    "\n",
    "    # Load and display original image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get annotated image\n",
    "    annotated_img = results[0].plot()\n",
    "    annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(annotated_img)\n",
    "    ax2.set_title('YOLO Detection Results')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print detection details\n",
    "    num_detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "    print(f\"üéØ Found {num_detections} objects:\")\n",
    "\n",
    "    if num_detections > 0:\n",
    "        for i, box in enumerate(results[0].boxes):\n",
    "            class_id = int(box.cls)\n",
    "            confidence = float(box.conf)\n",
    "            class_name = model.names[class_id]\n",
    "            print(f\"   {i+1}. {class_name} (confidence: {confidence:.2f})\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment and modify path to test custom images):\n",
    "test_custom_image(model, '/home/cupo-ubuntu/Schreibtisch/ML4B/wastenet-model/github/data/batch_1/000111.JPG')\n",
    "\n",
    "print(\"üí° To test custom images, use: test_custom_image(model, 'path/to/image.jpg')\")"
   ],
   "id": "13ed5780a8f70709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 12: Export Models for Deployment (SIMPLE FIX)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"üì¶ Exporting model for deployment...\")\n",
    "\n",
    "# SIMPLE FIX: Move model to CPU first to avoid GPU export issues\n",
    "model.to('cpu')\n",
    "\n",
    "export_dir = './exported_models'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Export to ONNX (for React website)\n",
    "try:\n",
    "    onnx_path = model.export(format='onnx', imgsz=640, half=False, simplify=False)\n",
    "    print(f\"‚úÖ ONNX model exported: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ONNX export failed: {e}\")\n",
    "\n",
    "# Export to TensorFlow Lite (for Android)\n",
    "try:\n",
    "    tflite_path = model.export(format='tflite', imgsz=640, half=False)\n",
    "    print(f\"‚úÖ TensorFlow Lite model exported: {tflite_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå TFLite export failed: {e}\")\n",
    "\n",
    "# Keep PyTorch model (for server deployment)\n",
    "import shutil\n",
    "pt_dest = os.path.join(export_dir, 'taco_model.pt')\n",
    "shutil.copy(model_path, pt_dest)\n",
    "print(f\"‚úÖ PyTorch model copied: {pt_dest}\")\n",
    "\n",
    "print(\"\\nüìã Model Export Summary:\")\n",
    "print(f\"üåê React website: Use ONNX model\")\n",
    "print(f\"üì± Android app: Use TFLite model\")\n",
    "print(f\"üñ•Ô∏è  Server deployment: Use PyTorch model\")"
   ],
   "id": "1f3efce9001d63b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 13: Final Training Summary and Report\n",
    "from datetime import datetime\n",
    "\n",
    "# Collect training information\n",
    "training_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"dataset\": {\n",
    "        \"name\": \"TACO\",\n",
    "        \"total_images\": len(images),\n",
    "        \"total_annotations\": len(annotations),\n",
    "        \"original_classes\": len(categories),\n",
    "        \"mapped_classes\": len(mapped_categories),\n",
    "        \"train_images\": train_images,\n",
    "        \"val_images\": val_images,\n",
    "        \"images_used\": train_images + val_images,\n",
    "        \"usage_rate\": f\"{((train_images + val_images)/len(images))*100:.1f}%\"\n",
    "    },\n",
    "    \"class_mapping\": {\n",
    "        \"original_to_mapped\": class_mapping,\n",
    "        \"mapped_categories\": mapped_categories,\n",
    "        \"reduction_ratio\": f\"{len(categories)} ‚Üí {len(mapped_categories)} ({((len(categories) - len(mapped_categories))/len(categories)*100):.1f}% reduction)\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"architecture\": \"YOLOv8n\",\n",
    "        \"pretrained\": True,\n",
    "        \"epochs\": 100,\n",
    "        \"image_size\": 640,\n",
    "        \"batch_size\": 16\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"val_mAP50\": float(val_metrics.box.map50),\n",
    "        \"val_mAP50_95\": float(val_metrics.box.map),\n",
    "        \"val_precision\": float(val_metrics.box.mp),\n",
    "        \"val_recall\": float(val_metrics.box.mr),\n",
    "        \"train_mAP50\": float(train_metrics.box.map50),\n",
    "        \"train_mAP50_95\": float(train_metrics.box.map),\n",
    "        \"overfitting_gap\": float(map50_diff),\n",
    "        \"inference_speed_ms\": float(val_metrics.speed['inference'])\n",
    "    },\n",
    "    \"fixes_applied\": {\n",
    "        \"filename_collision_fix\": True,\n",
    "        \"class_mapping\": True,\n",
    "        \"dataset_usage_improvement\": f\"From 498 to {train_images + val_images} images\"\n",
    "    },\n",
    "    \"files\": {\n",
    "        \"model_path\": model_path,\n",
    "        \"config_path\": './output/data.yaml',\n",
    "        \"results_dir\": results_dir,\n",
    "        \"mapping_info\": './output/class_mapping_info.json'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_path = './training_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(training_summary, f, indent=2)\n",
    "\n",
    "print(\"üìä TRAINING COMPLETED SUCCESSFULLY! üéâ\")\n",
    "print(\"=\"*70)\n",
    "print(\"üìã FINAL SUMMARY:\")\n",
    "print(f\"   üéØ Final Validation mAP50: {val_metrics.box.map50:.3f}\")\n",
    "print(f\"   üìà Training mAP50: {train_metrics.box.map50:.3f}\")\n",
    "print(f\"   üîÑ Overfitting Gap: {map50_diff:+.3f}\")\n",
    "print(f\"   ‚ö° Inference Speed: {val_metrics.speed['inference']:.1f}ms\")\n",
    "print(f\"   üìâ Class Reduction: {len(categories)} ‚Üí {len(mapped_categories)} classes\")\n",
    "print(f\"   üìä Dataset Usage: {train_images + val_images:,}/{len(images):,} images ({((train_images + val_images)/len(images))*100:.1f}%)\")\n",
    "print(f\"   üìÅ Model Location: {model_path}\")\n",
    "print(f\"   üìÑ Summary Report: {summary_path}\")\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ Your COLLISION-FIXED TACO object detection model is ready!\")\n",
    "\n",
    "# Display final class distribution\n",
    "print(f\"\\nüè∑Ô∏è  FINAL MAPPED CLASSES ({len(mapped_categories)} total):\")\n",
    "for i, cat in enumerate(mapped_categories):\n",
    "    yolo_id = mapped_category_to_yolo_id[cat]\n",
    "    count = mapped_counts[cat]\n",
    "    percentage = (count / sum(mapped_counts.values())) * 100\n",
    "    print(f\"   {yolo_id}: {cat:25} - {count:4} samples ({percentage:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nüí° FIXES APPLIED SUCCESSFULLY:\")\n",
    "print(f\"   ‚úÖ Filename collision prevention (batch names included)\")\n",
    "print(f\"   ‚úÖ Full dataset utilization ({train_images + val_images:,} images)\")\n",
    "print(f\"   ‚úÖ Class mapping and balance improvement\")\n",
    "print(f\"   ‚úÖ Enhanced training configuration\")\n",
    "print(f\"   ‚úÖ Comprehensive evaluation (train + validation)\")\n",
    "\n",
    "improvement_factor = (train_images + val_images) / 498\n",
    "print(f\"\\nüöÄ PERFORMANCE IMPROVEMENT EXPECTED:\")\n",
    "print(f\"   üìà {improvement_factor:.1f}x more training data\")\n",
    "print(f\"   üéØ Should see significant mAP improvement\")\n",
    "print(f\"   ‚ö° Better generalization to new images\")\n",
    "print(f\"   üîß Ready for real-world deployment!\")"
   ],
   "id": "2af23c87ee38e446",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
